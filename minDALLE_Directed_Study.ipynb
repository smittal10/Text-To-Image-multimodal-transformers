{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nfB7EUcdzogi",
   "metadata": {
    "id": "nfB7EUcdzogi"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kakaobrain/minDALL-E.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q_bMMl1m4fCD",
   "metadata": {
    "id": "q_bMMl1m4fCD"
   },
   "outputs": [],
   "source": [
    "!pip install -U torchtext==0.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install torch==1.10 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fc2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1iOdGU5E25Yr",
   "metadata": {
    "id": "1iOdGU5E25Yr"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wl049mDfIhAb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wl049mDfIhAb",
    "outputId": "04c14a2f-cb2d-4b4a-f7d0-211391cf6cb4"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Iw1khxFhjVMW",
   "metadata": {
    "id": "Iw1khxFhjVMW"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf36725-ec00-4027-95d6-374340c2264e",
   "metadata": {
    "id": "cdf36725-ec00-4027-95d6-374340c2264e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import clip\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DRY9tCO0JzsV",
   "metadata": {
    "id": "DRY9tCO0JzsV"
   },
   "outputs": [],
   "source": [
    "from dalle.models import Dalle\n",
    "from dalle.utils.utils import set_seed, clip_score\n",
    "\n",
    "# device = 'cuda:0'\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2622ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_vVGgtsyJ2sx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "_vVGgtsyJ2sx",
    "outputId": "0f3c851d-2538-4c02-a600-3c08e64576e7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Dalle.from_pretrained(\"minDALL-E/1.3B\")\n",
    "model_clip, preprocess_clip = clip.load(\"ViT-B/32\")\n",
    "\n",
    "model_clip.to(device=device)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OsiV6duLW3ae",
   "metadata": {
    "id": "OsiV6duLW3ae"
   },
   "outputs": [],
   "source": [
    "def sampling(prompt, top_k, softmax_temperature, seed, num_candidates=96, num_samples_for_display=36, folder='',filename=''):\n",
    "    # Setup\n",
    "    n_row = int(math.sqrt(num_samples_for_display))\n",
    "    n_col = int(math.sqrt(num_samples_for_display))\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # Sampling\n",
    "    images = model.sampling(prompt=prompt,\n",
    "                            top_k=top_k,\n",
    "                            top_p=None,\n",
    "                            softmax_temperature=softmax_temperature,\n",
    "                            num_candidates=num_candidates,\n",
    "                            device=device).cpu().numpy()\n",
    "    images = np.transpose(images, (0, 2, 3, 1))\n",
    "\n",
    "    # CLIP Re-ranking\n",
    "    rank = clip_score(prompt=prompt, images=images, model_clip=model_clip, preprocess_clip=preprocess_clip, device=device)\n",
    "    images = images[rank]\n",
    "    \n",
    "    images = images[:num_samples_for_display]\n",
    "    \n",
    "    if not os.path.exists(f'images/{folder}/'):\n",
    "        os.makedirs(f'images/{folder}/')\n",
    "    # return images\n",
    "    for i,image in enumerate(images):\n",
    "        im1 = Image.fromarray(np.uint8((images[i])*255))\n",
    "        im1.save(f\"images/{folder}/{filename}-r{i+1}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619add15-073e-40f4-9a97-06b89d647c81",
   "metadata": {
    "id": "619add15-073e-40f4-9a97-06b89d647c81"
   },
   "outputs": [],
   "source": [
    "# if not os.path.exists('images/test/'):\n",
    "#     os.makedirs('images/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ef515",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2], device='cuda:0')\n",
    "a + torch.tensor([1],device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dg0OMOrAVn6z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg0OMOrAVn6z",
    "outputId": "52ed3dbe-8afb-4f27-f039-f02d01f680ad"
   },
   "outputs": [],
   "source": [
    "images = sampling(prompt=\"a man sleeping with his cat next to him\", top_k=196, softmax_temperature=1, seed=15, num_candidates=20, num_samples_for_display=10, folder='onetest',filename='man_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a950df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mscoco_male_captions.csv\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for idx,line in enumerate(lines[50:]):\n",
    "        line = line.strip('\\n').strip('.').strip().split(',')\n",
    "        print(line)\n",
    "#         break\n",
    "        sampling(prompt=line[2], top_k=256, softmax_temperature=1, seed=15, num_candidates=5, num_samples_for_display=5, folder='mscoco_male',filename=f\"male_{idx+50}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158c2eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mscoco_female_captions.csv\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for idx,line in enumerate(lines[1:]):\n",
    "        line = line.strip('\\n').strip('.').strip().split(',')\n",
    "        print(line)\n",
    "#         break\n",
    "        sampling(prompt=line[2], top_k=256, softmax_temperature=1, seed=15, num_candidates=5, num_samples_for_display=5, folder='mscoco_female',filename=f\"female_{idx+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AChKTMCVbNM8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AChKTMCVbNM8",
    "outputId": "c3be1eb5-9f54-43c4-9c58-05218e71324d"
   },
   "outputs": [],
   "source": [
    "# with open(\"negated_captions/negated_val_captions.txt\",'r') as f:\n",
    "#     lines = f.readlines()\n",
    "#     for line in lines:\n",
    "#         line = line.strip('\\n').strip('.').strip()\n",
    "#         sampling(prompt=line, top_k=196, softmax_temperature=1, seed=15, num_candidates=5, num_samples_for_display=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Geb8wsFXMBj",
   "metadata": {
    "id": "-Geb8wsFXMBj"
   },
   "outputs": [],
   "source": [
    "# im1 = Image.fromarray(np.uint8((images[0])*255))\n",
    "# # Image.fromarray(np.uint8(numpy_image)).convert('RGB')\n",
    "# im1.save(f\"generated_images/hello-1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a191a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir('images/mscoco_male/'), key=lambda x: (int(x.split('_')[1].split('-')[0]), int(x.split('_')[1].split('-')[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = preprocess_clip(Image.open(\"images/mscoco_male/male_1-r2.jpg\")).unsqueeze(0).to(device)\n",
    "text = clip.tokenize([\"a man\", \"a woman\"]).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_features = model_clip.encode_image(image)\n",
    "    text_features = model_clip.encode_text(text)\n",
    "    \n",
    "    logits_per_image, logits_per_text = model_clip(image, text)\n",
    "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "    \n",
    "print(\"Label probs:\", probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_class(im_path):\n",
    "    image = preprocess_clip(Image.open(im_path)).unsqueeze(0).to(device)\n",
    "    text = clip.tokenize([\"a man\", \"a woman\"]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = model_clip.encode_image(image)\n",
    "        text_features = model_clip.encode_text(text)\n",
    "\n",
    "        logits_per_image, logits_per_text = model_clip(image, text)\n",
    "        probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
    "\n",
    "        \n",
    "        print(\"Label probs:\", probs)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37870243",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('images/mscoco_male/'), key=lambda x: (int(x.split('_')[1].split('-')[0]), int(x.split('_')[1].split('-')[1][1])))\n",
    "results = []\n",
    "for im_path in image_paths:\n",
    "    probs = gender_class(f\"images/mscoco_male/{im_path}\")\n",
    "    results.append((im_path,probs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3926cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('images/mscoco_female/'), key=lambda x: (int(x.split('_')[1].split('-')[0]), int(x.split('_')[1].split('-')[1][1])))\n",
    "female_results = []\n",
    "for im_path in image_paths:\n",
    "    probs = gender_class(f\"images/mscoco_female/{im_path}\")\n",
    "    female_results.append((im_path,probs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZEkBGlng2Fq_",
   "metadata": {
    "id": "ZEkBGlng2Fq_"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f5878",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a49d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval male results\n",
    "threshold = 0.9\n",
    "male_labels = []\n",
    "for row in results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    male_labels.append((name,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c762b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval male results\n",
    "threshold = 0.9\n",
    "female_labels = []\n",
    "for row in female_results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    female_labels.append((name,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4fd0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "male_df = pd.DataFrame(male_labels,columns=['img_name','label'])\n",
    "female_df = pd.DataFrame(female_labels,columns=['img_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82650475",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddef0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f438c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9875d991",
   "metadata": {},
   "source": [
    "--- Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mscoco_female_unobvious_captions.csv\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for idx,line in enumerate(lines[1:]):\n",
    "        line = line.strip('\\n').strip('.').strip().split(',')\n",
    "        print(line)\n",
    "#         break\n",
    "        sampling(prompt=line[2], top_k=256, softmax_temperature=1, seed=15, num_candidates=5, num_samples_for_display=5, folder='mscoco_unobvious_female',filename=f\"unobvious_female_{idx+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/mscoco_male_unobvious_captions.csv\",'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for idx,line in enumerate(lines[1:]):\n",
    "        line = line.strip('\\n').strip('.').strip().split(',')\n",
    "        print(line)\n",
    "#         break\n",
    "        sampling(prompt=line[2], top_k=256, softmax_temperature=1, seed=15, num_candidates=5, num_samples_for_display=5, folder='mscoco_unobvious_male',filename=f\"unobvious_male_{idx+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2300f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('images/mscoco_unobvious_male/'), key=lambda x: (int(x.split('_')[2].split('-')[0]), int(x.split('_')[2].split('-')[1][1])))\n",
    "male_unobv_results = []\n",
    "for im_path in image_paths:\n",
    "    probs = gender_class(f\"images/mscoco_unobvious_male/{im_path}\")\n",
    "    male_unobv_results.append((im_path,probs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eaab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('images/mscoco_unobvious_female/'), key=lambda x: (int(x.split('_')[2].split('-')[0]), int(x.split('_')[2].split('-')[1][1])))\n",
    "female_unobv_results = []\n",
    "for im_path in image_paths:\n",
    "    probs = gender_class(f\"images/mscoco_unobvious_female/{im_path}\")\n",
    "    female_unobv_results.append((im_path,probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('images/mscoco_unobvious_female/')), len(os.listdir('images/mscoco_unobvious_male/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09077fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval male results\n",
    "threshold = 0.9\n",
    "unobvious_male_labels = []\n",
    "for row in male_unobv_results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    unobvious_male_labels.append((name,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9588a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval male results\n",
    "threshold = 0.9\n",
    "unobvious_female_labels = []\n",
    "for row in female_unobv_results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    unobvious_female_labels.append((name,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "male_df = pd.DataFrame(unobvious_male_labels,columns=['img_name','label'])\n",
    "female_df = pd.DataFrame(unobvious_female_labels,columns=['img_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb93d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23165a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da359a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count() / len(male_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count() / len(female_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8eb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "662a82af",
   "metadata": {},
   "source": [
    "------ threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a534a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#eval male results\n",
    "threshold = 0.8\n",
    "unobvious_male_labels = []\n",
    "for row in male_unobv_results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    unobvious_male_labels.append((name,label))\n",
    "\n",
    "#eval male results\n",
    "threshold = 0.8\n",
    "unobvious_female_labels = []\n",
    "for row in female_unobv_results:\n",
    "    name = row[0]\n",
    "    logits = row[1][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    unobvious_female_labels.append((name,label))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "male_df = pd.DataFrame(unobvious_male_labels,columns=['img_name','label'])\n",
    "female_df = pd.DataFrame(unobvious_female_labels,columns=['img_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d228b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac78cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count() / len(male_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f9f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count() / len(female_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1b227",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f50883",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('CogView/male_generations/'))\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dd0f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3414cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_paths[0].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f67b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_paths = sorted(os.listdir('CogView/male_generations/'), key=lambda x: (int(x.split('_')[2].split('-')[0]), int(x.split('_')[2].split('-')[1][1])))\n",
    "\n",
    "processed_paths = []\n",
    "for path in image_paths:\n",
    "    if 'concat' not in path:\n",
    "        processed_paths.append(path)\n",
    "\n",
    "male_cog_results = []\n",
    "for im_path in processed_paths:\n",
    "    probs = gender_class(f\"CogView/male_generations/{im_path}\")\n",
    "    text = path.split('_')[0]\n",
    "    male_cog_results.append((text,im_path,probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa51dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_paths = sorted(os.listdir('CogView/female_generations/'))\n",
    "processed_paths = []\n",
    "for path in image_paths:\n",
    "    if 'concat' not in path:\n",
    "        processed_paths.append(path)\n",
    "\n",
    "female_cog_results = []\n",
    "for im_path in processed_paths:\n",
    "    probs = gender_class(f\"CogView/female_generations/{im_path}\")\n",
    "    text = path.split('_')[0]\n",
    "    female_cog_results.append((text,im_path,probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7244564",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(male_cog_results), len(female_cog_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186982d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "cog_male_labels = []\n",
    "for row in male_cog_results:\n",
    "    text = row[0]\n",
    "    file_path = row[1]\n",
    "    logits = row[2][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    cog_male_labels.append((text,file_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "cog_female_labels = []\n",
    "for row in female_cog_results:\n",
    "    text = row[0]\n",
    "    file_path = row[1]\n",
    "    logits = row[2][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    cog_female_labels.append((text,file_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "male_df = pd.DataFrame(cog_male_labels,columns=['text','img_name','label'])\n",
    "female_df = pd.DataFrame(cog_female_labels,columns=['text','img_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc48264",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe77a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff128e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb92149",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "cog_male_labels = []\n",
    "for row in male_cog_results:\n",
    "    text = row[0]\n",
    "    file_path = row[1]\n",
    "    logits = row[2][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    cog_male_labels.append((text,file_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65882486",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "cog_female_labels = []\n",
    "for row in female_cog_results:\n",
    "    text = row[0]\n",
    "    file_path = row[1]\n",
    "    logits = row[2][0]\n",
    "    \n",
    "    if logits[0] >=threshold:\n",
    "        label = 'male'\n",
    "    elif logits[1] >= threshold:\n",
    "        label= 'female'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    cog_female_labels.append((text,file_path,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b821015",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df = pd.DataFrame(cog_male_labels,columns=['text','img_name','label'])\n",
    "female_df = pd.DataFrame(cog_female_labels,columns=['text','img_name','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c755a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47a639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3c791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "minDALLE - Directed Study.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
